{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Quantum Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install pre-requisites required for this notebook to run\n",
    "\n",
    "**Note:** This step is optional if you are running this from the docker container"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m\u001b[1m    Updating\u001b[22m\u001b[39m registry at `~/.julia/registries/General`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n",
      "\u001b[32m\u001b[1m   Resolving\u001b[22m\u001b[39m package versions...\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Project.toml`\n",
      "\u001b[32m\u001b[1m  No Changes\u001b[22m\u001b[39m to `~/.julia/environments/v1.6/Manifest.toml`\n"
     ]
    }
   ],
   "source": [
    "using Pkg;\n",
    "\n",
    "Pkg.add(\"PyCall\");\n",
    "Pkg.add(\"AWS\");\n",
    "\n",
    "Pkg.add(\"Flux\");\n",
    "Pkg.add(\"MLDatasets\");\n",
    "\n",
    "Pkg.add(\"Plots\");\n",
    "Pkg.add(\"PyPlot\");\n",
    "Pkg.add(\"ProgressMeter\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "using Flux: onehotbatch, onecold, onehot;\n",
    "using Flux.Data: DataLoader\n",
    "using Flux;\n",
    "\n",
    "using PyCall\n",
    "using AWS: @service\n",
    "@service S3;\n",
    "@service Braket;\n",
    "@service STS;\n",
    "\n",
    "using MLDatasets\n",
    "using Colors\n",
    "using Plots\n",
    "using ProgressMeter;\n",
    "\n",
    "# Braket imports\n",
    "awsbraket = pyimport(\"braket.aws\");\n",
    "devices   = pyimport(\"braket.devices\");\n",
    "circuit   = pyimport(\"braket.circuits\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to use the LocalSimulator to run this notebook, so that we don't incur any cost."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "qpu = devices.LocalSimulator();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classical Deep Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform binary classification with classical deep learning, we need four components:\n",
    "\n",
    "**A Dataset**\n",
    "\n",
    "The $d$-dimensional data along with the ground-truth labels for each datapoint. \n",
    "\n",
    "$$\n",
    "D = (X, Y)\n",
    "$$\n",
    "\n",
    "$$\n",
    "X = \\{x_1, x_2,.. x_n\\}; \\quad x \\in \\Bbb R^d\n",
    "$$\n",
    "\n",
    "$$\n",
    "Y = \\{y_1, y_2, ... y_n\\}; \\quad y \\in \\Bbb \\{0,1\\}\n",
    "$$\n",
    "\n",
    "**A Neural Network Model with Trainable Parameters**\n",
    "\n",
    "A set of weights that can be applied to the model. The model uses these weights combined with the data to make a decision.\n",
    "\n",
    "$$\n",
    "f_{N N}(x ; \\theta)=\\sigma(W x+b);  \\quad \\theta=\\{W, b\\}\n",
    "$$\n",
    "\n",
    "**An Objective Function**\n",
    "\n",
    "Tells us how accurate/inaccurate the model is from the correct solution for a particular set of datapoints.\n",
    "\n",
    "$$\n",
    "C=\\sum_{\\text {data } \\mathrm{x}, \\mathrm{y}}|f(x ; \\theta)-y|^{2}\n",
    "$$\n",
    "\n",
    "**An Optimization Routine**\n",
    "\n",
    "For a given set of trainable parameters, the optimization routine tells us how to change the trainable parameters to minimize the objective function. \n",
    "\n",
    "$$\n",
    "\\theta^{(t+1)}=\\theta^{(t)}-\\eta \\nabla_{\\theta} C\n",
    "$$\n",
    "\n",
    "In classical machine learning, there are several options for each of the aforementioned components.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quantum Machine Learning\n",
    "\n",
    "![Schuld, Maria, and Francesco Petruccione. Supervised learning with quantum computers. Vol. 17. Berlin: Springer, 2018.](assets/landscape.png \"Quantum Machine Learning Landscape\")\n",
    "\n",
    "If we divide the machine learning landscape on the axis of the data generation device and the data processing device, it can fall into one of the four categories described below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**CC:** Classical data processed by Classical algorithms\n",
    "\n",
    "\n",
    "**CQ:** Classical data processed by Quantum algorithms\n",
    "\n",
    "\n",
    "**QC:** Quantum data processed by Classical algorithms. (i.e) Machine Learning *for* quantum computing.\n",
    "\n",
    "\n",
    "**QQ:** Quantum data processed by Quantum algorithms\n",
    "\n",
    "Quantum Machine Learning can refer to either the **CQ** scenario or the **QQ** scenario. Although the most interesting applications are in **QQ**, there are very few results in this direction [7]. In this notebook, we will focus on a **CQ** application - classical data processed by quantum algorithms. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Data\n",
    "\n",
    "The function below computes the parity of a given bit string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bit string: 1011 | Parity: 1\n",
      "Bit string: 1001 | Parity: 0\n"
     ]
    }
   ],
   "source": [
    "function parity(bitStr)\n",
    "    return count(i->(i=='1'), bitStr) % 2\n",
    "end;\n",
    "\n",
    "println(\"Bit string: 1011 | Parity: \", parity(\"1011\"))\n",
    "println(\"Bit string: 1001 | Parity: \", parity(\"1001\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate data, we will take all bit strings of size $n$ and label them as $0$ if they have an even parity and $1$ if they have odd parity. We use ~70% of the data for training and ~30% of the data for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBits = 5;\n",
    "\n",
    "trainSet = []\n",
    "testSet = []\n",
    "\n",
    "trainLabel = []\n",
    "testLabel = []\n",
    "\n",
    "for ind in 1:2^nBits-1\n",
    "    if rand() < 0.30\n",
    "        bitStr = join(string.(digits(ind, base=2, pad=nBits)))\n",
    "        push!(testSet, bitStr)\n",
    "        push!(testLabel, parity(bitStr))\n",
    "    else\n",
    "        bitStr = join(string.(digits(ind, base=2, pad=nBits)))\n",
    "        push!(trainSet, bitStr)\n",
    "        push!(trainLabel, parity(bitStr))\n",
    "    end;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's sample a few data points from the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data: 11011 | Label: 0\n",
      "Data: 00010 | Label: 1\n",
      "Data: 11111 | Label: 1\n",
      "Data: 11111 | Label: 1\n",
      "Data: 01001 | Label: 0\n"
     ]
    }
   ],
   "source": [
    "for i in 1:5\n",
    "    ind = rand(1:length(trainSet))\n",
    "    println(\"Data: \", trainSet[ind], \" | Label: \", trainLabel[ind])\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To build a quantum machine learning model, we can leverage *variational quantum circuits*. Variational Quantum Circuits are quantum circuits with parameters that can be *trained* much the same way as neural networks can be."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](assets/VQC.png \"Variational Quantum Circuits\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### State Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to map our classical bitstring into quantum states. We map classical bit values 0 and 1 onto quantum states |0〉 and |1〉, respectively. \n",
    "\n",
    "By convention, the initial state of a qubit is always assumed to be |0〉. If a quantum algorithm requires the input quantum state to be |1〉, then we obtain it from |0〉by applying a qubit flip gate $X$ \n",
    "\n",
    "$$|1〉 = X |0〉$$ \n",
    "\n",
    "Below we provide code that generates a quantum circuit for preparing an arbitrary multi-qubit computational basis state |$\\psi_i$ 〉using the Amazon Braket SDK. Unlike Julia, the Braket SDK uses 0 based qubit indexing. Although not strictly necessary, we add identity gates for indices with 0 in the bitstring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "function bit_string_to_circuit(bitStr)\n",
    "    circ = circuit.Circuit()\n",
    "    \n",
    "    for i=firstindex(bitStr):lastindex(bitStr)\n",
    "        if bitStr[i] == '1'\n",
    "            circ.add(circuit.Circuit().x(i-1))\n",
    "        else\n",
    "            circ.add(circuit.Circuit().i(i-1))\n",
    "        end\n",
    "    end\n",
    "    \n",
    "    return circ\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can visualize how our function converted the bit string by using the Amazon Braket SDK's diagram function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T  : |0|\n",
      "        \n",
      "q0 : -X-\n",
      "        \n",
      "q1 : -I-\n",
      "        \n",
      "q2 : -X-\n",
      "        \n",
      "q3 : -I-\n",
      "\n",
      "T  : |0|\n"
     ]
    }
   ],
   "source": [
    "println(bit_string_to_circuit(\"1010\").diagram())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quantum Circuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our parity detection example, we will use a quantum circuit with $N+1$ qubits. The $N$ bit bitstring is encoded in the first $N$ qubits labelled $\\{0, N-1\\}$. The $(N+1)^{th}$ qubit labelled $N$ is used to store the output binary label assigned to the bitstring. We first apply the RY gate to the first $N$ qubits and the $RX$ gate to the $(N+1)^{th}$ qubit. The XX rotation gate is applied to each qubit with the ${0, N}$ qubits as the control qubits and the $(N+1)^{th}$ qubit as the target qubit. We then consider the angles for each of the rotation gates in the circuit as optimization parameters. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![M Fischer, D Brooks, P Lougovski, and T Takeshita - 2021](assets/qml_parity.jpg \"Quantum Neural Network\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code below implements this QNN, applies it to an arbitrary input state defined by a classical bit string, and measures the values of the label qubit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "function QNN(bitStr, pars)\n",
    "    nQbts = length(bitStr)\n",
    "    qnn = circuit.Circuit()\n",
    "    qnn.add(circuit.Circuit().rx(nQbts, pars[1]))\n",
    "    for i = 1:length(bitStr)\n",
    "        angles = pars[2 * (i - 1) + 1:2 * (i - 1) + 1 + 2]\n",
    "        if bitStr[i] == '1'\n",
    "            qnn.add(circuit.Circuit().x(i - 1))\n",
    "        end\n",
    "        qnn.add(circuit.Circuit().ry(i - 1, angles[2]))\n",
    "        if i <= nQbts\n",
    "            qnn.add(circuit.Circuit().xx(i - 1, nQbts, angles[3]))\n",
    "        end\n",
    "    end\n",
    "    observZ = circuit.Observable.Z()\n",
    "    return qnn.add(circuit.Circuit().expectation(observZ, target=[nQbts]))\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's apply random parameters to the QNN with a bit string of length 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T  : |  0  |  1  |  2  |  3  |  4  |  5  | Result Types |\n",
      "                                                         \n",
      "q0 : -X-----Ry(2)-XX(3)----------------------------------\n",
      "                  |                                      \n",
      "q1 : -Ry(4)-------|-----XX(5)----------------------------\n",
      "                  |     |                                \n",
      "q2 : -X-----Ry(6)-|-----|-----XX(7)----------------------\n",
      "                  |     |     |                          \n",
      "q3 : -Ry(8)-------|-----|-----|-----XX(9)----------------\n",
      "                  |     |     |     |                    \n",
      "q4 : -Rx(1)-------XX(3)-XX(5)-XX(7)-XX(9)-Expectation(Z)-\n",
      "\n",
      "T  : |  0  |  1  |  2  |  3  |  4  |  5  | Result Types |\n"
     ]
    }
   ],
   "source": [
    "sampleNBits = 4\n",
    "value = \"1010\"\n",
    "weights = 1:(sampleNBits * 2 + 1)\n",
    "circ = QNN(value, weights)\n",
    "println(circ.diagram())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Circuit Parameters\n",
    "\n",
    "We can initialize the parameters $\\theta$ to use with our QNN. We start with a random initialization between $[-\\pi,\\pi]$. Overall, we have $2n+1$ parameters to optimize, where $n$ is the number of bits in our bitstring - 2 for each qubit and 1 for the result qubit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "W = rand(-pi:pi, nBits * 2 + 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Objective Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To generate a prediction from our QNN circuit, we can define a utility function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "function predict(bitStr, params)\n",
    "    qpu = devices.LocalSimulator()\n",
    "    circ = QNN(bitStr, params)\n",
    "\n",
    "    activation = qpu.run(circ, shots=0).result().values[1]\n",
    "    \n",
    "    return (1 - activation) / 2\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can try out this utility function with a random bitstring and random weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model predicted: 0.0616878900186284 | Actual Parity: 1\n"
     ]
    }
   ],
   "source": [
    "value = \"1011\"\n",
    "weights = rand(-pi:pi,(4*2+1))\n",
    "println(\"Model predicted: \", predict(value, weights), \" | \", \"Actual Parity: \", parity(value))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the mean-square error as a metric to identify how far off we are from the ideal solution. The mean square error is:\n",
    "\n",
    "$$\n",
    "MSE(Y, \\hat{Y}) = \\frac{\\Sigma_{i=0}^N y_i - \\hat{y}_i}{N}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "function square_loss(labels, predictions)\n",
    "    loss = 0\n",
    "    \n",
    "    for (i, label) in enumerate(labels)\n",
    "        loss+=(labels[i] - predictions[i])^2\n",
    "    end\n",
    "    \n",
    "    return loss/length(labels)[1]\n",
    "end;\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cost function defined below computes the mean squared error for the entire training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "function cost(var, features, labels)\n",
    "    preds = []\n",
    "    for feature in features\n",
    "        prediction = predict(feature, var)\n",
    "        push!(preds,prediction)\n",
    "    end;\n",
    "    lossVal = square_loss(labels, preds)\n",
    "    \n",
    "    return lossVal\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2920935109779255"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cost(rand(-pi:pi, nBits*2 + 1),trainSet[1:5], trainLabel[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization Routine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of the components we need for our QNN, we can use standard optimization techniques to find our optimal parameters $\\theta$. \n",
    "\n",
    "**How can we compute the gradients for our optimization routine?** [5]\n",
    "\n",
    "Consider the following function:\n",
    "\n",
    "$$\n",
    "f(\\theta) = sin(\\theta)\n",
    "$$\n",
    "\n",
    "the gradient of this function is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta} f(\\theta)=cos(\\theta)\n",
    "$$\n",
    "\n",
    "\n",
    "$cos(\\theta)$ can be expressed as:\n",
    "\n",
    "$$\n",
    "\\cos \\theta=\\frac{\\sin \\left(\\theta+\\frac{\\pi}{4}\\right)-\\sin \\left(\\theta-\\frac{\\pi}{4}\\right)}{\\sqrt{2}}\n",
    "$$\n",
    "\n",
    "Therefore, the derivate in terms of the original function $f(\\theta)$ is:\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta} f(\\theta)=\\frac{f\\left(\\theta+\\frac{\\pi}{2}\\right)-f\\left(\\theta-\\frac{\\pi}{2}\\right)}{2}\n",
    "$$\n",
    "\n",
    "which means that we can obtain the derivative of this function, evaluating it twice, once by forward shifting it by $\\frac{\\pi}{2}$ and ond once by backward shifting it by $\\frac{\\pi}{2}$\n",
    "\n",
    "If we can evaluate this function, we can also evaluate it's derivative, using the \"parameter-shift rule\"\n",
    "\n",
    "$$\n",
    "\\frac{\\partial}{\\partial \\theta} f(\\theta)=c[f(\\theta+s)-f(\\theta-s)]\n",
    "$$\n",
    "\n",
    "This property holds for certain classes of functions, such as those with trigonometric structure.\n",
    "\n",
    "Quantum gates \"admit\" the parameter-shift property. We can use the parameter-shift rule on our circuits to get the exact gradient of our variational circuit, with respect to our parameters.\n",
    "\n",
    "The parameter shift rule is exact, but is affected by the underlying measurement noise.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, the gradient of the expectation value can be calculated by evaluating the same variational quantum circuit, but with shifted parameter values \\[[2](https://pennylane.ai/qml/demos/tutorial_backprop.html)\\]. The value of the shift depends on the gates. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "function parameter_shift_term(dataset, labels, params, i)\n",
    "    shifted = copy(params)\n",
    "    \n",
    "    shifted[i] += pi/2\n",
    "    plus = cost(shifted, dataset, labels)\n",
    "    \n",
    "    shifted[i] -= pi\n",
    "    minus = cost(shifted, dataset, labels)\n",
    "    \n",
    "    return 0.5 * (plus - minus)\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "function parameter_shift(dataset, labels, params)\n",
    "    gradients = zeros(size(params)[1])\n",
    "    \n",
    "    for i in 1:size(params)[1]\n",
    "        gradients[i] = parameter_shift_term(dataset, labels, params, i)\n",
    "    end;\n",
    "    \n",
    "    return gradients;\n",
    "end;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a way to get the direction in which the parameters need to be updated, we can use ADAM to perform the actual optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = ADAM(0.1);\n",
    "W = rand(-pi:pi, nBits * 2 + 1);\n",
    "trainingLoss = [];\n",
    "parameter_shift(trainSet, trainLabel, W);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32mProgress: 100%|█████████████████████████████████████████| Time: 0:03:40\u001b[39m\n"
     ]
    }
   ],
   "source": [
    "epochs = 100;\n",
    "@showprogress for i in 1:epochs\n",
    "    Flux.Optimise.update!(opt, W, parameter_shift(trainSet, trainLabel, W))\n",
    "    push!(trainingLoss, cost(W, trainSet, trainLabel))\n",
    "end;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
       "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"600\" height=\"400\" viewBox=\"0 0 2400 1600\">\n",
       "<defs>\n",
       "  <clipPath id=\"clip190\">\n",
       "    <rect x=\"0\" y=\"0\" width=\"2400\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip190)\" d=\"\n",
       "M0 1600 L2400 1600 L2400 0 L0 0  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip191\">\n",
       "    <rect x=\"480\" y=\"0\" width=\"1681\" height=\"1600\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<path clip-path=\"url(#clip190)\" d=\"\n",
       "M156.112 1486.45 L2352.76 1486.45 L2352.76 47.2441 L156.112 47.2441  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<defs>\n",
       "  <clipPath id=\"clip192\">\n",
       "    <rect x=\"156\" y=\"47\" width=\"2198\" height=\"1440\"/>\n",
       "  </clipPath>\n",
       "</defs>\n",
       "<polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  197.349,1486.45 197.349,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  720.658,1486.45 720.658,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1243.97,1486.45 1243.97,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  1767.28,1486.45 1767.28,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  2290.59,1486.45 2290.59,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 2352.76,1486.45 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  197.349,1486.45 197.349,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  720.658,1486.45 720.658,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1243.97,1486.45 1243.97,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1767.28,1486.45 1767.28,1469.18 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2290.59,1486.45 2290.59,1469.18 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip190)\" d=\"M197.349 1515.64 Q193.738 1515.64 191.909 1519.2 Q190.104 1522.75 190.104 1529.87 Q190.104 1536.98 191.909 1540.55 Q193.738 1544.09 197.349 1544.09 Q200.983 1544.09 202.789 1540.55 Q204.617 1536.98 204.617 1529.87 Q204.617 1522.75 202.789 1519.2 Q200.983 1515.64 197.349 1515.64 M197.349 1511.93 Q203.159 1511.93 206.215 1516.54 Q209.293 1521.12 209.293 1529.87 Q209.293 1538.6 206.215 1543.21 Q203.159 1547.79 197.349 1547.79 Q191.539 1547.79 188.46 1543.21 Q185.405 1538.6 185.405 1529.87 Q185.405 1521.12 188.46 1516.54 Q191.539 1511.93 197.349 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M699.929 1543.18 L716.249 1543.18 L716.249 1547.12 L694.304 1547.12 L694.304 1543.18 Q696.966 1540.43 701.55 1535.8 Q706.156 1531.15 707.337 1529.81 Q709.582 1527.28 710.462 1525.55 Q711.364 1523.79 711.364 1522.1 Q711.364 1519.34 709.42 1517.61 Q707.499 1515.87 704.397 1515.87 Q702.198 1515.87 699.744 1516.63 Q697.314 1517.4 694.536 1518.95 L694.536 1514.23 Q697.36 1513.09 699.814 1512.51 Q702.267 1511.93 704.304 1511.93 Q709.675 1511.93 712.869 1514.62 Q716.063 1517.31 716.063 1521.8 Q716.063 1523.93 715.253 1525.85 Q714.466 1527.74 712.36 1530.34 Q711.781 1531.01 708.679 1534.23 Q705.577 1537.42 699.929 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M726.11 1512.56 L744.466 1512.56 L744.466 1516.5 L730.392 1516.5 L730.392 1524.97 Q731.411 1524.62 732.429 1524.46 Q733.448 1524.27 734.466 1524.27 Q740.253 1524.27 743.633 1527.44 Q747.012 1530.62 747.012 1536.03 Q747.012 1541.61 743.54 1544.71 Q740.068 1547.79 733.749 1547.79 Q731.573 1547.79 729.304 1547.42 Q727.059 1547.05 724.651 1546.31 L724.651 1541.61 Q726.735 1542.74 728.957 1543.3 Q731.179 1543.86 733.656 1543.86 Q737.661 1543.86 739.999 1541.75 Q742.336 1539.64 742.336 1536.03 Q742.336 1532.42 739.999 1530.31 Q737.661 1528.21 733.656 1528.21 Q731.781 1528.21 729.906 1528.62 Q728.054 1529.04 726.11 1529.92 L726.11 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M1218.67 1512.56 L1237.02 1512.56 L1237.02 1516.5 L1222.95 1516.5 L1222.95 1524.97 Q1223.97 1524.62 1224.99 1524.46 Q1226 1524.27 1227.02 1524.27 Q1232.81 1524.27 1236.19 1527.44 Q1239.57 1530.62 1239.57 1536.03 Q1239.57 1541.61 1236.1 1544.71 Q1232.63 1547.79 1226.31 1547.79 Q1224.13 1547.79 1221.86 1547.42 Q1219.62 1547.05 1217.21 1546.31 L1217.21 1541.61 Q1219.29 1542.74 1221.51 1543.3 Q1223.74 1543.86 1226.21 1543.86 Q1230.22 1543.86 1232.56 1541.75 Q1234.89 1539.64 1234.89 1536.03 Q1234.89 1532.42 1232.56 1530.31 Q1230.22 1528.21 1226.21 1528.21 Q1224.34 1528.21 1222.46 1528.62 Q1220.61 1529.04 1218.67 1529.92 L1218.67 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M1258.78 1515.64 Q1255.17 1515.64 1253.34 1519.2 Q1251.54 1522.75 1251.54 1529.87 Q1251.54 1536.98 1253.34 1540.55 Q1255.17 1544.09 1258.78 1544.09 Q1262.42 1544.09 1264.22 1540.55 Q1266.05 1536.98 1266.05 1529.87 Q1266.05 1522.75 1264.22 1519.2 Q1262.42 1515.64 1258.78 1515.64 M1258.78 1511.93 Q1264.59 1511.93 1267.65 1516.54 Q1270.73 1521.12 1270.73 1529.87 Q1270.73 1538.6 1267.65 1543.21 Q1264.59 1547.79 1258.78 1547.79 Q1252.97 1547.79 1249.89 1543.21 Q1246.84 1538.6 1246.84 1529.87 Q1246.84 1521.12 1249.89 1516.54 Q1252.97 1511.93 1258.78 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M1741.13 1512.56 L1763.35 1512.56 L1763.35 1514.55 L1750.81 1547.12 L1745.92 1547.12 L1757.73 1516.5 L1741.13 1516.5 L1741.13 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M1772.52 1512.56 L1790.88 1512.56 L1790.88 1516.5 L1776.8 1516.5 L1776.8 1524.97 Q1777.82 1524.62 1778.84 1524.46 Q1779.86 1524.27 1780.88 1524.27 Q1786.66 1524.27 1790.04 1527.44 Q1793.42 1530.62 1793.42 1536.03 Q1793.42 1541.61 1789.95 1544.71 Q1786.48 1547.79 1780.16 1547.79 Q1777.98 1547.79 1775.71 1547.42 Q1773.47 1547.05 1771.06 1546.31 L1771.06 1541.61 Q1773.15 1542.74 1775.37 1543.3 Q1777.59 1543.86 1780.07 1543.86 Q1784.07 1543.86 1786.41 1541.75 Q1788.75 1539.64 1788.75 1536.03 Q1788.75 1532.42 1786.41 1530.31 Q1784.07 1528.21 1780.07 1528.21 Q1778.19 1528.21 1776.32 1528.62 Q1774.46 1529.04 1772.52 1529.92 L1772.52 1512.56 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M2250.19 1543.18 L2257.83 1543.18 L2257.83 1516.82 L2249.52 1518.49 L2249.52 1514.23 L2257.79 1512.56 L2262.46 1512.56 L2262.46 1543.18 L2270.1 1543.18 L2270.1 1547.12 L2250.19 1547.12 L2250.19 1543.18 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M2289.55 1515.64 Q2285.93 1515.64 2284.11 1519.2 Q2282.3 1522.75 2282.3 1529.87 Q2282.3 1536.98 2284.11 1540.55 Q2285.93 1544.09 2289.55 1544.09 Q2293.18 1544.09 2294.98 1540.55 Q2296.81 1536.98 2296.81 1529.87 Q2296.81 1522.75 2294.98 1519.2 Q2293.18 1515.64 2289.55 1515.64 M2289.55 1511.93 Q2295.36 1511.93 2298.41 1516.54 Q2301.49 1521.12 2301.49 1529.87 Q2301.49 1538.6 2298.41 1543.21 Q2295.36 1547.79 2289.55 1547.79 Q2283.73 1547.79 2280.66 1543.21 Q2277.6 1538.6 2277.6 1529.87 Q2277.6 1521.12 2280.66 1516.54 Q2283.73 1511.93 2289.55 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M2319.71 1515.64 Q2316.1 1515.64 2314.27 1519.2 Q2312.46 1522.75 2312.46 1529.87 Q2312.46 1536.98 2314.27 1540.55 Q2316.1 1544.09 2319.71 1544.09 Q2323.34 1544.09 2325.15 1540.55 Q2326.98 1536.98 2326.98 1529.87 Q2326.98 1522.75 2325.15 1519.2 Q2323.34 1515.64 2319.71 1515.64 M2319.71 1511.93 Q2325.52 1511.93 2328.57 1516.54 Q2331.65 1521.12 2331.65 1529.87 Q2331.65 1538.6 2328.57 1543.21 Q2325.52 1547.79 2319.71 1547.79 Q2313.9 1547.79 2310.82 1543.21 Q2307.76 1538.6 2307.76 1529.87 Q2307.76 1521.12 2310.82 1516.54 Q2313.9 1511.93 2319.71 1511.93 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1445.72 2352.76,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,1024.36 2352.76,1024.36 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,603.009 2352.76,603.009 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip192)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:2; stroke-opacity:0.1; fill:none\" points=\"\n",
       "  156.112,181.656 2352.76,181.656 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1486.45 156.112,47.2441 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1445.72 182.472,1445.72 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,1024.36 182.472,1024.36 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,603.009 182.472,603.009 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  156.112,181.656 182.472,181.656 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip190)\" d=\"M62.9365 1431.51 Q59.3254 1431.51 57.4967 1435.08 Q55.6912 1438.62 55.6912 1445.75 Q55.6912 1452.86 57.4967 1456.42 Q59.3254 1459.96 62.9365 1459.96 Q66.5707 1459.96 68.3763 1456.42 Q70.205 1452.86 70.205 1445.75 Q70.205 1438.62 68.3763 1435.08 Q66.5707 1431.51 62.9365 1431.51 M62.9365 1427.81 Q68.7467 1427.81 71.8022 1432.42 Q74.8809 1437 74.8809 1445.75 Q74.8809 1454.48 71.8022 1459.08 Q68.7467 1463.67 62.9365 1463.67 Q57.1264 1463.67 54.0477 1459.08 Q50.9921 1454.48 50.9921 1445.75 Q50.9921 1437 54.0477 1432.42 Q57.1264 1427.81 62.9365 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M83.0984 1457.12 L87.9827 1457.12 L87.9827 1463 L83.0984 1463 L83.0984 1457.12 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M108.168 1431.51 Q104.557 1431.51 102.728 1435.08 Q100.922 1438.62 100.922 1445.75 Q100.922 1452.86 102.728 1456.42 Q104.557 1459.96 108.168 1459.96 Q111.802 1459.96 113.608 1456.42 Q115.436 1452.86 115.436 1445.75 Q115.436 1438.62 113.608 1435.08 Q111.802 1431.51 108.168 1431.51 M108.168 1427.81 Q113.978 1427.81 117.033 1432.42 Q120.112 1437 120.112 1445.75 Q120.112 1454.48 117.033 1459.08 Q113.978 1463.67 108.168 1463.67 Q102.358 1463.67 99.2789 1459.08 Q96.2234 1454.48 96.2234 1445.75 Q96.2234 1437 99.2789 1432.42 Q102.358 1427.81 108.168 1427.81 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M64.1634 1010.16 Q60.5523 1010.16 58.7236 1013.73 Q56.918 1017.27 56.918 1024.4 Q56.918 1031.5 58.7236 1035.07 Q60.5523 1038.61 64.1634 1038.61 Q67.7976 1038.61 69.6031 1035.07 Q71.4318 1031.5 71.4318 1024.4 Q71.4318 1017.27 69.6031 1013.73 Q67.7976 1010.16 64.1634 1010.16 M64.1634 1006.46 Q69.9735 1006.46 73.029 1011.06 Q76.1077 1015.65 76.1077 1024.4 Q76.1077 1033.12 73.029 1037.73 Q69.9735 1042.31 64.1634 1042.31 Q58.3532 1042.31 55.2745 1037.73 Q52.219 1033.12 52.219 1024.4 Q52.219 1015.65 55.2745 1011.06 Q58.3532 1006.46 64.1634 1006.46 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M84.3253 1035.76 L89.2095 1035.76 L89.2095 1041.64 L84.3253 1041.64 L84.3253 1035.76 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M100.205 1037.71 L107.844 1037.71 L107.844 1011.34 L99.5335 1013.01 L99.5335 1008.75 L107.797 1007.08 L112.473 1007.08 L112.473 1037.71 L120.112 1037.71 L120.112 1041.64 L100.205 1041.64 L100.205 1037.71 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M64.5337 588.808 Q60.9226 588.808 59.0939 592.373 Q57.2884 595.914 57.2884 603.044 Q57.2884 610.15 59.0939 613.715 Q60.9226 617.257 64.5337 617.257 Q68.168 617.257 69.9735 613.715 Q71.8022 610.15 71.8022 603.044 Q71.8022 595.914 69.9735 592.373 Q68.168 588.808 64.5337 588.808 M64.5337 585.104 Q70.3439 585.104 73.3994 589.711 Q76.4781 594.294 76.4781 603.044 Q76.4781 611.771 73.3994 616.377 Q70.3439 620.96 64.5337 620.96 Q58.7236 620.96 55.6449 616.377 Q52.5893 611.771 52.5893 603.044 Q52.5893 594.294 55.6449 589.711 Q58.7236 585.104 64.5337 585.104 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M84.6956 614.41 L89.5799 614.41 L89.5799 620.289 L84.6956 620.289 L84.6956 614.41 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M103.793 616.354 L120.112 616.354 L120.112 620.289 L98.1678 620.289 L98.1678 616.354 Q100.83 613.599 105.413 608.97 Q110.02 604.317 111.2 602.974 Q113.445 600.451 114.325 598.715 Q115.228 596.956 115.228 595.266 Q115.228 592.511 113.283 590.775 Q111.362 589.039 108.26 589.039 Q106.061 589.039 103.608 589.803 Q101.177 590.567 98.3993 592.118 L98.3993 587.396 Q101.223 586.262 103.677 585.683 Q106.131 585.104 108.168 585.104 Q113.538 585.104 116.733 587.789 Q119.927 590.474 119.927 594.965 Q119.927 597.095 119.117 599.016 Q118.33 600.914 116.223 603.507 Q115.645 604.178 112.543 607.396 Q109.441 610.59 103.793 616.354 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M63.5847 167.455 Q59.9736 167.455 58.1449 171.019 Q56.3393 174.561 56.3393 181.691 Q56.3393 188.797 58.1449 192.362 Q59.9736 195.903 63.5847 195.903 Q67.2189 195.903 69.0244 192.362 Q70.8531 188.797 70.8531 181.691 Q70.8531 174.561 69.0244 171.019 Q67.2189 167.455 63.5847 167.455 M63.5847 163.751 Q69.3948 163.751 72.4503 168.357 Q75.529 172.941 75.529 181.691 Q75.529 190.417 72.4503 195.024 Q69.3948 199.607 63.5847 199.607 Q57.7745 199.607 54.6958 195.024 Q51.6403 190.417 51.6403 181.691 Q51.6403 172.941 54.6958 168.357 Q57.7745 163.751 63.5847 163.751 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M83.7466 193.056 L88.6308 193.056 L88.6308 198.936 L83.7466 198.936 L83.7466 193.056 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M112.983 180.302 Q116.339 181.019 118.214 183.288 Q120.112 185.556 120.112 188.89 Q120.112 194.005 116.594 196.806 Q113.075 199.607 106.594 199.607 Q104.418 199.607 102.103 199.167 Q99.8113 198.751 97.3576 197.894 L97.3576 193.38 Q99.3021 194.515 101.617 195.093 Q103.932 195.672 106.455 195.672 Q110.853 195.672 113.145 193.936 Q115.459 192.2 115.459 188.89 Q115.459 185.834 113.307 184.121 Q111.177 182.385 107.358 182.385 L103.33 182.385 L103.33 178.542 L107.543 178.542 Q110.992 178.542 112.82 177.177 Q114.649 175.788 114.649 173.195 Q114.649 170.533 112.751 169.121 Q110.876 167.686 107.358 167.686 Q105.436 167.686 103.237 168.103 Q101.038 168.519 98.3993 169.399 L98.3993 165.232 Q101.061 164.492 103.376 164.121 Q105.714 163.751 107.774 163.751 Q113.098 163.751 116.2 166.181 Q119.302 168.589 119.302 172.709 Q119.302 175.579 117.658 177.57 Q116.015 179.538 112.983 180.302 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><polyline clip-path=\"url(#clip192)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  218.281,97.945 239.214,87.9763 260.146,119.591 281.078,191.396 302.011,273.899 322.943,360.658 343.876,464.278 364.808,585.922 385.74,710.623 406.673,828.508 \n",
       "  427.605,939.409 448.537,1042.15 469.47,1141.12 490.402,1243.08 511.335,1337.48 532.267,1403.56 553.199,1434.84 574.132,1443.54 595.064,1444.94 615.996,1443.29 \n",
       "  636.929,1435.66 657.861,1422.35 678.794,1408.63 699.726,1400.21 720.658,1400.02 741.591,1407.41 762.523,1419.03 783.456,1430.61 804.388,1439.1 825.32,1443.68 \n",
       "  846.253,1445.34 867.185,1445.66 888.117,1445.67 909.05,1445.53 929.982,1445.09 950.915,1444.34 971.847,1443.54 992.779,1443.03 1013.71,1443.03 1034.64,1443.52 \n",
       "  1055.58,1444.26 1076.51,1444.96 1097.44,1445.43 1118.37,1445.65 1139.31,1445.71 1160.24,1445.72 1181.17,1445.71 1202.1,1445.68 1223.04,1445.62 1243.97,1445.54 \n",
       "  1264.9,1445.49 1285.83,1445.5 1306.76,1445.56 1327.7,1445.63 1348.63,1445.68 1369.56,1445.71 1390.49,1445.71 1411.43,1445.72 1432.36,1445.72 1453.29,1445.71 \n",
       "  1474.22,1445.71 1495.16,1445.7 1516.09,1445.7 1537.02,1445.7 1557.95,1445.7 1578.89,1445.71 1599.82,1445.71 1620.75,1445.71 1641.68,1445.72 1662.62,1445.72 \n",
       "  1683.55,1445.72 1704.48,1445.72 1725.41,1445.71 1746.34,1445.71 1767.28,1445.71 1788.21,1445.71 1809.14,1445.71 1830.07,1445.72 1851.01,1445.72 1871.94,1445.72 \n",
       "  1892.87,1445.72 1913.8,1445.72 1934.74,1445.72 1955.67,1445.72 1976.6,1445.72 1997.53,1445.72 2018.47,1445.72 2039.4,1445.72 2060.33,1445.72 2081.26,1445.72 \n",
       "  2102.2,1445.72 2123.13,1445.72 2144.06,1445.72 2164.99,1445.72 2185.92,1445.72 2206.86,1445.72 2227.79,1445.72 2248.72,1445.72 2269.65,1445.72 2290.59,1445.72 \n",
       "  \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip190)\" d=\"\n",
       "M1983.03 216.178 L2279.53 216.178 L2279.53 95.2176 L1983.03 95.2176  Z\n",
       "  \" fill=\"#ffffff\" fill-rule=\"evenodd\" fill-opacity=\"1\"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#000000; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  1983.03,216.178 2279.53,216.178 2279.53,95.2176 1983.03,95.2176 1983.03,216.178 \n",
       "  \"/>\n",
       "<polyline clip-path=\"url(#clip190)\" style=\"stroke:#009af9; stroke-linecap:butt; stroke-linejoin:round; stroke-width:4; stroke-opacity:1; fill:none\" points=\"\n",
       "  2007.44,155.698 2153.88,155.698 \n",
       "  \"/>\n",
       "<path clip-path=\"url(#clip190)\" d=\"M2192.13 175.385 Q2190.33 180.015 2188.61 181.427 Q2186.9 182.839 2184.03 182.839 L2180.63 182.839 L2180.63 179.274 L2183.13 179.274 Q2184.89 179.274 2185.86 178.44 Q2186.83 177.607 2188.01 174.505 L2188.78 172.561 L2178.29 147.052 L2182.8 147.052 L2190.91 167.329 L2199.01 147.052 L2203.52 147.052 L2192.13 175.385 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /><path clip-path=\"url(#clip190)\" d=\"M2210.81 169.042 L2218.45 169.042 L2218.45 142.677 L2210.14 144.343 L2210.14 140.084 L2218.41 138.418 L2223.08 138.418 L2223.08 169.042 L2230.72 169.042 L2230.72 172.978 L2210.81 172.978 L2210.81 169.042 Z\" fill=\"#000000\" fill-rule=\"evenodd\" fill-opacity=\"1\" /></svg>\n"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot(trainingLoss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the QNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature:01010| QNN predicted parity: 0 | Actual Parity: 0\n",
      "---------------------------------------------------\n",
      "Feature:00110| QNN predicted parity: 0 | Actual Parity: 0\n",
      "---------------------------------------------------\n",
      "Feature:01110| QNN predicted parity: 1 | Actual Parity: 1\n",
      "---------------------------------------------------\n",
      "Feature:11110| QNN predicted parity: 0 | Actual Parity: 0\n",
      "---------------------------------------------------\n",
      "Feature:10101| QNN predicted parity: 1 | Actual Parity: 1\n",
      "---------------------------------------------------\n",
      "Feature:11101| QNN predicted parity: 0 | Actual Parity: 0\n",
      "---------------------------------------------------\n",
      "Feature:00011| QNN predicted parity: 0 | Actual Parity: 0\n",
      "---------------------------------------------------\n",
      "Feature:00111| QNN predicted parity: 1 | Actual Parity: 1\n",
      "---------------------------------------------------\n",
      "Overall cost: 4.611887964881845e-9\n"
     ]
    }
   ],
   "source": [
    "for (ind, data) in enumerate(testSet)\n",
    "    prediction = predict(data, W)\n",
    "    println(\"Feature:\", data, \"| QNN predicted parity: \", 0 + (prediction > 0.5), \" | \", \"Actual Parity: \", parity(data))\n",
    "    println(\"---------------------------------------------------\")\n",
    "end\n",
    "\n",
    "println(\"Overall cost: \", cost(W, testSet, testLabel))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Suggestions for Further Exploration\n",
    "\n",
    "- What happens if you change the variational circuit used to generate the prediction?\n",
    "- What are some other techniques for transforming classical data?\n",
    "- What are some other technique for optimizing variational circuits?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\[1\\] [Using Quantum Machine Learning with Amazon Braket to Create a Binary Classifier](https://aws.amazon.com/blogs/quantum-computing/aioi-using-quantum-machine-learning-with-amazon-braket-to-create-a-binary-classifier/)\n",
    "\n",
    "\\[2\\] [Quantum gradients with backpropagation](https://pennylane.ai/qml/demos/tutorial_backprop.html)\n",
    "\n",
    "\\[3\\] [Training](https://fluxml.ai/Flux.jl/stable/training/training/)\n",
    "\n",
    "\\[4\\] [Quantum Computing Learning Series 10: Training a Quantum Circuit](https://broadcast.amazon.com/videos/307498)\n",
    "\n",
    "\\[5\\] [Automatic Differentiation of Quantum Circuits](https://www.youtube.com/watch?v=McgBeSVIGus)\n",
    "\n",
    "\\[6\\] [Introduction to Quantum Machine Learning with PennyLane](https://www.youtube.com/playlist?list=PL_hJxz_HrXxsQNJHWp10up8x-hwd5uwr0)\n",
    "\n",
    "\\[7\\] [Supervised Learning\n",
    "with Quantum Computers](https://ndl.ethernet.edu.et/bitstream/123456789/73371/1/320.pdf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.6.1",
   "language": "julia",
   "name": "julia-1.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
